---
title: "RCT Data Management"
date: '`r Sys.Date()`'
toc: TRUE
embed-resources: true
---

# Introduction

Data Management code for the **S**creening, **S**elf-**M**anagement, and **R**eferral to **T**reatment (SSMRT) project.

This code accomplishes a few things:

-   Fetches data files (either locally or directly from REDCap)

-   Verifies participant IP addresses, compared against self-reported location

-   Various data quality checks

    -   Long-string analysis (also known as straight-lining)

    -   Speeding

    -   Inconsistency/attention checks

-   Publishes recruitment statistics

More detail for each of these steps can be found in their corresponding sections.

Contact the project administrators at [aloverock\@ualberta.ca](mailto:aloverock@ualberta.ca) and/or [jacob.belliveau\@dal.ca](mailto:jacob.belliveau@dal.ca) for the files and keys needed to run.

```{r data init}

library(REDCapR)

# if the "keys.R" file does not exist, choose local filenames
if (!file.exists("keys.R")) {
  
  #baseline filename
  baseline_filename <- file.choose(new = TRUE)
  
  # intervention filenames
  i1_filename <- file.choose(new = TRUE)
  i2_filename <- file.choose(new = TRUE)
  
  # control filenames
  c1_filename <- file.choose(new = TRUE)
  c2_filename <- file.choose(new = TRUE)
} else {
  
  # running the file containing keys
  source("keys.R")
  
  # fetching baseline datasets
  baseline_df <- redcap_read_oneshot(DAL_URI, BASELINE_API_KEY)$data
  
  # fetching intervention datasets
  int1_df <- redcap_read_oneshot(DAL_URI, I1_API_KEY)$data
  int2_df <- redcap_read_oneshot(DAL_URI, I2_API_KEY)$data
  
  # fetching control datasets
  ctl1_df <- redcap_read_oneshot(DAL_URI, C1_API_KEY)$data
  ctl2_df <- redcap_read_oneshot(DAL_URI, C2_API_KEY)$data
  
  # clearing unneeded keys from the environment
  rm(BASELINE_API_KEY, I1_API_KEY, I2_API_KEY, C1_API_KEY, C2_API_KEY, DAL_URI)
  
}

```

# Data Linkage {#sec-data-linkage}

The data for this study consists of 5 main datasets: the baseline survey, and 2 datasets for each followup for both the control and intervention groups. The code below combines these datasets into one data set.

The follow-up datasets for control and intervention are combined into one data set, with the fields for each survey being assigned the suffix "\_F1" or "\_F2" to indicate variables that belong to follow-up 1 or 2, respectively. This results in two datasets (one for control, one for intervention) which each have the same sets of variables. The control and intervention datasets are then combined by appending the rows from one group into the other. As a final step, the baseline and follow-up datasets are then combined.

Note that matching at each applicable step is done using participant access codes. These access codes are assigned by the SSMRT platform and are unique to each participant. Thus, participants without access codes are discarded (as this is indicative of link tampering).

It is possible for access codes to be duplicated in any of the given 4 follow-up datasets. This is possible as participants are emailed the link to the survey; if they click that link multiple times, they will have multiple entries in the survey with the same access codes. For simplicity, we consider only the "latest" entry into the survey as valid for duplicate participants; other attempts are discarded.

```{r data linkage}

library(tidyr)
library(dplyr)

### first combining into wide format

# first correcting the final variable of the dataset (binary variable indicating if they finished the survey; different name for each survey)

ctl1_df <- rename(ctl1_df, 
       followup_complete = rct_follow_up_1_control_group_complete)
ctl2_df <- rename(ctl2_df, 
       followup_complete = rct_follow_up_2_control_group_complete)

int1_df <- rename(int1_df, 
       followup_complete = rct_follow_up_1_intervention_group_complete)
int2_df <- rename(int2_df, 
       followup_complete = rct_follow_up_2_intervention_group_complete)


# TODO: figure out how to deal with participants who complete follow up 2 but not 1
      # maybe checking that access codes in part 2 are also in part 1; if not, add a blank row to part 1 with just the access code?

# combining control follow-ups into one dataset
control <- full_join(ctl1_df, ctl2_df, by = "access_code", suffix = c("_F1", "_F2"), na_matches = "never")

# combining intervention follow-ups into one dataset
intervention <- full_join(int1_df, int2_df, by = "access_code", suffix = c("_F1", "_F2"), na_matches = "never")

# combining the intervention and control datasets
followup <- rbind(control, intervention)

# combining the follow-up surveys to baseline
# NOTE: here, participants without access codes in the follow-up are discarded
# NOTE: the "latest" response is kept for participants with duplicate access codes
df <- left_join(baseline_df, followup, by = "access_code", na_matches = "never", multiple = "last")

# removing temporary variables ; df will be used going forward
rm(control, intervention, followup, int1_df, int2_df, ctl1_df, ctl2_df, baseline_df)
```

# Participant validation

In the initial study link sent to participants, there are two unique identifiers provided to participants: R and S values. These identifiers are generated by the research team and consist of randomly generated patterns of letters and numbers. Specifically, the **R values** are 3 characters long and can only contain the numbers 1 to 9 (not 0) and the letters A, B, C, D, E, F, G, H, I , J, K, X, and Z. **S values** can contain any letter or number and are 10 characters long. At project initialization, the research team generated a list of 10,000 of each of these values. Each list of values was added to a spreadsheet, and it was recorded which email/participant was sent the link containing the pair of R/S identifiers. Thus, each pair of identifiers is unique and traceable to each participant. The code below serves to identify that 1) each R/S pair is unique (i.e., there are no duplicate participant entries), and 2) that each R/S pair is valid compared against the pre-generated list of R/S pairs.

## Duplicate participants

These participants are flagged for manual inspection by the research team. Once a decision is made for these participants, the decision is recorded in the code below. In general, participants who show attempts of trying to game the survey for extra compensation are excluded, and other genuine attempts are retained (e.g., participants who began the survey but did not complete it and restarted later, with responses being roughly consistent for each attempt). Signs of "gaming" the survey that were taken into consideration by the research team include:

-   Attempting the survey using multiple email addresses

-   Providing different demographic information across attempts

-   Failing the screening questions on the initial attempt, and re-trying the survey with different responses to the screening questions

## Participants with invalid R/S pairs

These participants are considered to be gaming the system without exception. This includes those with blank or undefined R/S values. These participants are unilaterally excluded from the final data set.

```{r validation}

library(openxlsx)

validpairs <- read.xlsx("SSMRT RS Values.xlsx", sheet = 1)

```

# Data quality checks

The sections below deal with various aspects of checking for data quality. The primary goal is verifying that participants are genuine and attentive.

## Participant location

Participant IP addresses are collected as they complete the baseline survey. Using [IPinfo](https://ipinfo.io/) and custom functions, participant province as reported by their IP address is compared against their self-reported province of residence. Participant province is cached locally.

If you are running this script once data collection is complete, only cached data will be used and no integration with IPinfo is needed.

```{r ip}



```

## Speeding

Participants are checked for speeding at the baseline. (Do we want to check at each step?)

Speeding in this case is defined as...

## Inconsistency checks

Several inconsistency checks

```{r cudit incon}



```

```{r age incon}



```

## Attention checks

Some attention checks

```{r select c}

df$attencheck

```

## Long-string analysis

Long-string analysis (also known as straight-lining) is checked using a custom function.

```{r longstring}



```

## Duplicate access codes

Duplicate access codes in the follow-up surveys are handled in [Data Linkage](#sec-data-linkage). Duplicate access codes at the baseline are handled below. This is not something which should happen often and is indicative of participants copying the initial survey link once they reach the screening questions. These participants are considered to be gaming the system, and are flagged for removal.

```{r duplicate acs}



```

# Report generation

The code below generates a report of relevant recruitment statistics and creates necessary files, as well as posting information to Google Sheets for ease of tracking.

If you are running this code once recruitment is complete, the reports requiring Google Authentication will be skipped.

## Placeholder report name

Report.

```{r report name}



```

## Google reporting

Reporting to Google Sheets.

```{r google reporting}



```

## Output files

All output files created by any part of code above are saved here.

```{r output}

# Checks for the existence of a folder in the project directory named ".output" - if it does not exist, creates it.
if (!dir.exists(".output")) {dir.create(".output")}

# Creates the folder name for today's output
todays_folder_name <- paste(".output", Sys.Date(), "", sep = "/")

# if the above folder doesn't exist, creates it
if (!dir.exists(todays_folder_name)) {dir.create(todays_folder_name)}




```
